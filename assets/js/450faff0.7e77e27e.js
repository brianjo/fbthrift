"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[9142],{3905:(e,t,n)=>{n.r(t),n.d(t,{MDXContext:()=>d,MDXProvider:()=>u,mdx:()=>f,useMDXComponents:()=>m,withMDXComponents:()=>p});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(){return o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var a in n)Object.prototype.hasOwnProperty.call(n,a)&&(e[a]=n[a])}return e},o.apply(this,arguments)}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=a.createContext({}),p=function(e){return function(t){var n=m(t.components);return a.createElement(e,o({},t,{components:n}))}},m=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},u=function(e){var t=m(e.components);return a.createElement(d.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),p=m(n),u=r,h=p["".concat(i,".").concat(u)]||p[u]||c[u]||o;return n?a.createElement(h,s(s({ref:t},d),{},{components:n})):a.createElement(h,s({ref:t},d))}));function f(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,i[1]=s;for(var d=2;d<o;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},29309:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>s,toc:()=>d});var a=n(83117),r=(n(67294),n(3905));const o={},i="Cpp2 ThriftServer",s={unversionedId:"cpp/cpp2",id:"cpp/cpp2",title:"Cpp2 ThriftServer",description:"This is a re-implementation of both the generated cpp code, and a",source:"@site/../doc/cpp/cpp2.md",sourceDirName:"cpp",slug:"/cpp/cpp2",permalink:"/docs/cpp/cpp2",draft:!1,editUrl:"https://github.com/facebook/fbthrift/blob/main/thrift/website/../doc/cpp/cpp2.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Channels in C++",permalink:"/docs/cpp/channel"},next:{title:"Internals",permalink:"/docs/internals/"}},l={},d=[{value:"Prerequisites",id:"prerequisites",level:3},{value:"Options",id:"options",level:3},{value:"Code example",id:"code-example",level:3},{value:"New generated code features",id:"new-generated-code-features",level:3},{value:"Serialization using IOBufs",id:"serialization-using-iobufs",level:3},{value:"Performance",id:"performance",level:3}],p={toc:d};function m(e){let{components:t,...o}=e;return(0,r.mdx)("wrapper",(0,a.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,r.mdx)("h1",{id:"cpp2-thriftserver"},"Cpp2 ThriftServer"),(0,r.mdx)("p",null,"This is a re-implementation of both the generated cpp code, and a\nfully asynchronous version of the c++ server code. In many ways it is\nsimilar to the older first-generation implementation:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Can run code inline, or in a ThreadManager queue.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Has a single acceptor thread, and hands off the accepts to IO\nthreads.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Has many options to handle server overload.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Uses libevent.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Maintains wire-format and IDL backwards compatibility."))),(0,r.mdx)("p",null,(0,r.mdx)("em",{parentName:"p"},"And many differences:")),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Updated for C++11.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Can optionally provide an asynchronous callback, or future\ninterface, as well as the previous synchronous server interface.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Responses can be sent to the client out of order, and processed in\nparallel.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Supports dynamic compression and tracing via the header.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Uses eventfd instead of pipes for notification.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Uses buffer chains\n(",(0,r.mdx)("a",{parentName:"p",href:"https://github.com/facebook/folly/blob/master/folly/io/IOBuf.h"},"folly/io/IOBuf.h"),")\nto prevent large allocations of memory.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Allows true zero-copy from client to server and back using IOBufs\n(vs. previous generated code that used std::string for binary type).")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"It's about 4x as fast as NonblockingServer in our load tests\n(",(0,r.mdx)("inlineCode",{parentName:"p"},"perf/cpp"),") for small requests. Latency is also much improved\ndepending on how parallel processing and out of order responses are\nused."))),(0,r.mdx)("h3",{id:"prerequisites"},"Prerequisites"),(0,r.mdx)("p",null,"This document assumes you are familiar with basic Thrift usage. We\nrecommend the following to become familiar:\n",(0,r.mdx)("a",{parentName:"p",href:"http://thrift.apache.org/"},"Apache Thrift"),",\n",(0,r.mdx)("a",{parentName:"p",href:"http://diwakergupta.github.io/thrift-missing-guide/"},"Thrift: The Missing Guide"),",\nand ",(0,r.mdx)("a",{parentName:"p",href:"http://jnb.ociweb.com/jnb/jnbJun2009.html"},"SETT on Apache Thrift"),"."),(0,r.mdx)("h3",{id:"options"},"Options"),(0,r.mdx)("p",null,"Useful (but not complete set of) options that can be set on the ThriftServer:"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setPort(int)")," - set port to listen on.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setIdleTimeout(std::chrono::milliseconds)")," - milliseconds before we close idle connections.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setTaskExpireTime(std::chrono::milliseconds)")," - milliseconds before\nwe timeout any individual request. This can also be set on a\nper-function bases by overriding the appropriate generated code\nmethod.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setNumIOWorkerThreads(int)")," - Number of IO async worker threads. Defaults to number of cores.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setNumCPUWorkerThreads(int)")," - Number of synchronous pool threads. Defaults\nto number of IO threads. If you do a lot of blocking synchronous\nwork, you may want to increase this. This controls the number of normal\npriority threads; the Thrift thread manager can create additional threads for\nother priorities.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setInterface(std::shared_ptr<ServerInterface>)")," - Your Thrift handler\ninterface that subclasses the generated code.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setMaxRequests(uint32_t)")," - The maximum number of outstanding\nrequests.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"setSSLContext(context)")," - Allow SSL connections."))),(0,r.mdx)("p",null,(0,r.mdx)("em",{parentName:"p"},"There are other options for specific use cases, such as")),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("inlineCode",{parentName:"li"},"setProcessorFactory(factory)")," - Not necessary if setInterface is\ncalled. Used for custom processors, usually proxies.")),(0,r.mdx)("h3",{id:"code-example"},"Code example"),(0,r.mdx)("p",null,"A service like the following"),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},"service TestService {\n  string sendResponse(1:i64 size)\n}\n")),(0,r.mdx)("p",null,"Will generate an interface similar to"),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},"class TestServiceSvIf : public TestServiceSvAsyncIf, public apache::thrift2::ServerInterface {\n  ...\n  virtual void sendResponse(std::string& _return, int64_t size);\n  virtual void async_sendResponse(std::unique_ptr<apache::thrift2::HandlerCallback<std::unique_ptr<std::string>>> callback, int64_t size) = 0;\n  virtual folly::Future<std::unique_ptr<std::string>> future_sendResponse(int64_t size);\n  ...\n}\n")),(0,r.mdx)("p",null,"So you have three choices of handler type to implement:"),(0,r.mdx)("ol",null,(0,r.mdx)("li",{parentName:"ol"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"sendResponse(...)")," is the synchronous method. It will be read and\ndeserialized in an IO thread, and then passed to a pool thread to be\nexecuted. When it returns, ",(0,r.mdx)("inlineCode",{parentName:"p"},"_return")," must contain the result, which\nwill be passed back to the original IO thread to serialize the\nresult and send it on the wire. You can block in this handler as\nlong as you wish, although you may need to tune the server more.")),(0,r.mdx)("li",{parentName:"ol"},(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("inlineCode",{parentName:"p"},"async_sendResponse(callback...)")," is a callback-style handler. The\nbase callback types are defined in ",(0,r.mdx)("a",{parentName:"p",href:"https://github.com/facebook/fbthrift/blob/master/thrift/lib/cpp2/async/AsyncProcessor.h"},"AsyncProcessor.h"),".\nYour handler method is called in the context of the receiving IO\nthread: This is meant so that you can make additional IO bound\ncalls. If you need to do CPU bound work, it would be better to\ntransfer it to the ThreadManager thread pool instead of blocking\nIO. Pseudocode Example:"))),(0,r.mdx)("pre",null,(0,r.mdx)("code",{parentName:"pre"},"    virtual void async_sendResponse(std::unique_ptr<apache::thrift2::HandlerCallback<std::unique_ptr<std::string>>> callback, int64_t size) {\n      auto client = getClient();\n      client->forwardSendRespose([=](Result& result){\n        callback->result(result);\n      }, size);\n    }\n")),(0,r.mdx)("p",null,"  (In production code, care would have to be taken with the lifetime\nof the callback object, and which thread it is called on. See\n",(0,r.mdx)("a",{parentName:"p",href:"https://github.com/facebook/fbthrift/blob/master/thrift/lib/cpp2/async/AsyncProcessor.h"},"AsyncProcessor.h")," for more info on Callback\nobjects)."),(0,r.mdx)("ol",{start:3},(0,r.mdx)("li",{parentName:"ol"},(0,r.mdx)("inlineCode",{parentName:"li"},"future_sendResponse(...)")," future interface\n","[",(0,r.mdx)("em",{parentName:"li"},"currently fb only"),"]",". Your handler must return a future object.\nWhen the future completes, the result will be sent.")),(0,r.mdx)("p",null,"You only need to override one of these methods in your handler. They\nwill be called in turn until an overridden method is found. If you do\nnot override any method, you will get a runtime error when the method\nis called."),(0,r.mdx)("h3",{id:"new-generated-code-features"},"New generated code features"),(0,r.mdx)("p",null,"The compiler was rewritten from scratch. We have found that adding\nnew features was difficult, especially where we needed to manage\nchanges to .h, .cpp, and .tcc files simultaneously. Instead, the\npython framework automatically knows which file changes need to go in."),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Compatibility mode: Typedefs generated structs to be the original\ncpp implementation. This is useful in that you can mix cpp and cpp2\ncode freely, assuming they are in different namespaces. This\nprecludes using some of the newer features below, however.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Full Zero Copy binary type: To change the default binary type to\nIOBuf, do something like"),(0,r.mdx)("pre",{parentName:"li"},(0,r.mdx)("code",{parentName:"pre"},'  typedef binary (cpp.type = "std::unique_ptr<folly::IOBuf>")\n  IOBufPtr\n')),(0,r.mdx)("p",{parentName:"li"},"You can also change the map and other complex types to whatever you\nwant this way.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"enum class: Enums are now generated with C++11's enum class\nfeature.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Arguments on heap: By default, complex arguments are on the heap, so\nthey can be moved between threads without a copy. To disable this,\nuse option ",(0,r.mdx)("inlineCode",{parentName:"p"},"stack_arguments"),".")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Optional / Required by default are the same as before. Using option\n",(0,r.mdx)("inlineCode",{parentName:"p"},"terse_writes")," will make it behave more like the dynamic\nlanguages: If the field is the same as the default value (or\nnothing if no default value is set), then it won't ever be sent on\nthe wire.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Support for floats was added."))),(0,r.mdx)("h3",{id:"serialization-using-iobufs"},"Serialization using IOBufs"),(0,r.mdx)("p",null,"An IOBuf is a network chained memory buffer, similar to FreeBSD's\nmbuf, or the Linux kernel's sk_buff. They can have the memory\ninternally if small enough, or externally malloced and shared. This is\nopaque to the user and done mostly for performance reasons, similar\nto fbstring. The IOBuf header itself can point to a subregion of the\nallocated memory, like a view."),(0,r.mdx)("p",null,"The main use in Thrift is to allow readahead for incoming data, and\nsupport chaining + writev for outgoing data. Both of these will reduce\nthe usage of expensive syscalls. A secondary advantage is that we only\nneed malloc small blocks of data at a time, which is much easier on\nthe allocator than trying to allocate large megabytes of data."),(0,r.mdx)("p",null,(0,r.mdx)("img",{alt:"IO Readahead",src:n(98017).Z,width:"594",height:"664"})),(0,r.mdx)("p",null,"When the Thrift channel reads the last part of a frame, it clones the\nIOBuf. There are now two 'views' on the same shared memory segment:\nOne part has the first part of the buffer (which is the last part of\nthe frame), the other is the last part of the buffer, which is the\nfirst part of the readahead data."),(0,r.mdx)("p",null,(0,r.mdx)("img",{alt:"IO Write Buffering",src:n(41275).Z,width:"892",height:"325"})),(0,r.mdx)("p",null,"Write buffering is similar but in reverse: When sending a response, we\nserialize it, then add it to an IOBuf queue. Once per TEventBase loop,\nwe call writeV with the whole of the queue."),(0,r.mdx)("h3",{id:"performance"},"Performance"),(0,r.mdx)("ul",null,(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"The standard memory allocator for glibc generally has high overhead,\nespecially in a threaded environment. There are two factors\ninvolved: locking and fragmentation. The glibc allocator uses a\nglobal mutex to allow threads to share a common heap. Since the heap\nis used extensively in Thrift serialization/deserialization and\nelsewhere (e.g. ",(0,r.mdx)("inlineCode",{parentName:"p"},"std::shared_ptr"),", ",(0,r.mdx)("inlineCode",{parentName:"p"},"std::bind"),") there is a great deal\nof contention for that lock. Alternative allocators such as\n",(0,r.mdx)("a",{parentName:"p",href:"https://www.facebook.com/jemalloc"},"jemalloc")," maintain per-thread\nheap resources such that locking is much less of an issue. They also\ntend to fragment memory less, though because allocation algorithms\ndiffer they can use more or less process memory than glibc. Although\ntcmalloc has been used with excellent results, jemalloc has in some\ncases demonstrated even better performance and has the advantage of\nbeing actively supported and enhanced by Facebook engineer Jason\nEvans.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"Using the load generator, we get some good numbers for QPS. This one\nis Noop's, one thread per core, and sending up to 100 outstanding\nrequests to fill up the buffer and show off the readahead / write\nqueueing. (Note that performance is similar to previous Thrift\nservers if there is only one outstanding request at a time). In\npractice, it seems raw qps for in-memory type servers (like\nkey-value store or similar) is at least 20% better than previous\nservers."),(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("img",{alt:"Thrift Noop Performance",src:n(47320).Z,width:"361",height:"435"})),(0,r.mdx)("p",{parentName:"li"},"To show off the out of order responses, we send a mix of burn (which\nhappens in a task queue), and noop. We would expect noop to have a\nmuch lower std dev if out of order is working properly."),(0,r.mdx)("p",{parentName:"li"},(0,r.mdx)("img",{alt:"Thrift Out Of Order Performance",src:n(37567).Z,width:"363",height:"434"})),(0,r.mdx)("p",{parentName:"li"},"(times in ms, QPS happen to be in k, but these numbers highly\ndependent on burn time) In practice, out of order does indeed\nreduce latency by almost 50% if your service has interleaved long\nand short requests, but we only saw the improvement at p75 and\nabove.")),(0,r.mdx)("li",{parentName:"ul"},(0,r.mdx)("p",{parentName:"li"},"The previous Thrift ThreadManager used mutexs and condition\nvariables to queue tasks and wake up threads. In practice, this\nlimited the throughput to around 300k qps. We have overhauled\nThreadManager to use a lockless MPMC queue, as well as adding LIFO\nworker thread semantics. This improved the throughput to just under\n1M qps. Unfortunately, it is still sensitive to tuning for the\nnumber of worker and IO threads, due to context switching overhead."))))}m.isMDXComponent=!0},98017:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/iobuf-readahead-8ef4babe7784bcd35010a78fda17871d.png"},41275:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/iobuf-write-buffering-301dea94fc9f60634d52296b7c74de7c.png"},47320:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/thrift2-server-noop-perf-4145a67e13b96a4e2e5981b475ebd04d.png"},37567:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/thrift2-server-out-of-order-perf-78989faf8d40011666f416be9360621f.png"}}]);